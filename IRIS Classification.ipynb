{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as sklearn_lm\n",
    "import matplotlib.pyplot as mp_plt\n",
    "import sklearn.multiclass as sklearn_mc\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_names = ['sepal length','sepal width','petal length', 'petal width', 'y']\n",
    "data = pd.read_csv('iris_dataset.txt', delimiter=',', names=data_names)\n",
    "data = data.values\n",
    "\n",
    "# define constants\n",
    "NUM_SAMPLES = data.shape[0]\n",
    "dr = 0.8\n",
    "NUM_TRAIN = int(NUM_SAMPLES * dr)\n",
    "NUM_TEST = NUM_SAMPLES - NUM_TRAIN\n",
    "NUM_CLASSES = 3\n",
    "NUM_ITER = 1\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "# preprocess data\n",
    "train_indexes = np.random.choice(NUM_SAMPLES, NUM_TRAIN, replace=False)\n",
    "test_indexes = np.setdiff1d(np.arange(0,NUM_SAMPLES), train_indexes, assume_unique=True)\n",
    "train_data = data[train_indexes]\n",
    "test_data = data[test_indexes]\n",
    "\n",
    "X_train = train_data[:,:-1]\n",
    "y_train = train_data[:,-1]\n",
    "X_test = test_data[:,:-1]\n",
    "y_test = test_data[:,-1]\n",
    "\n",
    "# training class labels\n",
    "label_idx = []\n",
    "for c in range(NUM_CLASSES):\n",
    "  label_idx.append(np.asarray([i for i in range(NUM_TRAIN) if y_train[i] == c+1]))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "data_plots = [[0,1],[0,2],[0,3],[1,2],[1,3],[2,3]]\n",
    "data_plots_name = [['SL','SW'],['SL','PL'],['SL','PW'],['SW','PL'],['SW','PW'],['PL','PW']]\n",
    "fig = mp_plt.figure(figsize=(24,16))\n",
    "for p in range(6):\n",
    "  mp_plt.subplot(2,3,p+1)\n",
    "  for i in range(NUM_CLASSES):\n",
    "    mp_plt.scatter(X_train[label_idx[i], data_plots[p][0]], \n",
    "                   X_train[label_idx[i], data_plots[p][1]], \n",
    "                   cmap=cmap_bold, label='Class: '+str(i+1))\n",
    "    mp_plt.xlabel(data_plots_name[p][0])\n",
    "    mp_plt.ylabel(data_plots_name[p][1])\n",
    "  mp_plt.legend()\n",
    "  \n",
    "mp_plt.savefig('figures/5.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class labels for testing\n",
    "label_idx_test = []\n",
    "for c in range(NUM_CLASSES):\n",
    "  label_idx_test.append(np.asarray([i for i in range(NUM_TEST) if y_test[i] == c+1]))\n",
    "\n",
    "# plot data\n",
    "data_color = ['magenta', 'orange', 'cyan']\n",
    "data_plots = [[0,1],[0,2],[0,3],[1,2],[1,3],[2,3]]\n",
    "data_plots_name = [['SL','SW'],['SL','PL'],['SL','PW'],['SW','PL'],['SW','PW'],['PL','PW']]\n",
    "fig = mp_plt.figure(figsize=(24,16))\n",
    "for p in range(6):\n",
    "  mp_plt.subplot(2,3,p+1)\n",
    "  for i in range(NUM_CLASSES):\n",
    "    mp_plt.scatter(X_test[label_idx_test[i], data_plots[p][0]], \n",
    "                   X_test[label_idx_test[i], data_plots[p][1]], \n",
    "                   cmap=cmap_bold, label='Class: '+str(i+1))\n",
    "    mp_plt.xlabel(data_plots_name[p][0])\n",
    "    mp_plt.ylabel(data_plots_name[p][1])\n",
    "  mp_plt.legend()\n",
    "  \n",
    "mp_plt.savefig('figures/6.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "data_color = ['magenta', 'orange', 'cyan']\n",
    "data_plots = [[0,1],[0,2],[0,3],[1,2],[1,3],[2,3]]\n",
    "data_plots_name = [['SL','SW'],['SL','PL'],['SL','PW'],['SW','PL'],['SW','PW'],['PL','PW']]\n",
    "fig = mp_plt.figure(figsize=(24,16))\n",
    "for p in range(6):\n",
    "  mp_plt.subplot(2,3,p+1)\n",
    "  for i in range(NUM_CLASSES):\n",
    "    mp_plt.scatter(X_train[label_idx[i], data_plots[p][0]], \n",
    "                   X_train[label_idx[i], data_plots[p][1]], \n",
    "                   c=data_color[i], label='Class: '+str(i+1))\n",
    "    mp_plt.xlabel(data_plots_name[p][0])\n",
    "    mp_plt.ylabel(data_plots_name[p][1])\n",
    "  mp_plt.legend()\n",
    "  \n",
    "mp_plt.savefig('figures/5.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshplot_multi(X, label_idx, clf, kwargs=None):    \n",
    "  h = 0.2 # meshgrid step\n",
    "  NUM_CLASSES = 3\n",
    "  cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "  cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "  cmap_color = ['#FF0000', '#00FF00', '#0000FF']\n",
    "  \n",
    "  # make meshgraid and decision regions\n",
    "  x1_min, x1_max = X[:,0].min() - 1, X[:, 0].max() + 1\n",
    "  x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "  xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, h),\n",
    "                       np.arange(x2_min, x2_max, h))\n",
    "  dbmesh_pred = clf.predict(np.c_[xx1.ravel(), xx2.ravel()])\n",
    "\n",
    "  # reshape and stack into color plot\n",
    "  dbmesh_pred = dbmesh_pred.reshape(xx1.shape)\n",
    "  mp_plt.figure()\n",
    "  fig = mp_plt.figure(figsize=(8,8))\n",
    "  mp_plt.pcolormesh(xx1, xx2, dbmesh_pred, cmap=cmap_light)\n",
    "\n",
    "  # plot training set\n",
    "  for i in range(NUM_CLASSES):\n",
    "    mp_plt.scatter(X[label_idx[i], 0], \n",
    "                   X[label_idx[i], 1], \n",
    "                   c=cmap_color[i], edgecolor='k', cmap=cmap_bold,\n",
    "                   label='Class: '+str(i+1))\n",
    "  mp_plt.xlim(xx1.min(), xx1.max())\n",
    "  mp_plt.ylim(xx2.min(), xx2.max())\n",
    "  if(kwargs):\n",
    "    mp_plt.xlabel(kwargs['x'])\n",
    "    mp_plt.ylabel(kwargs['y'])\n",
    "    mp_plt.title(kwargs['title'])\n",
    "  mp_plt.legend()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(y_test, y_pred):\n",
    "  return np.float64(sum(y_test == y_pred)) / np.float64(y_test.size)\n",
    "\n",
    "def linear_classifier(X_train, y_train, X_test, y_test, normalise_data, NUM_ITER):\n",
    "  if(normalise_data):\n",
    "    X_mu = np.mean(X_train, axis=0)\n",
    "    X_var = np.var(X_train, axis=0)\n",
    "    X_train = (X_train - X_mu) / np.sqrt(X_var)\n",
    "    X_test = (X_test - X_mu) / np.sqrt(X_var)\n",
    "  \n",
    "  # randomly sample data from both classes\n",
    "  acc = np.empty((NUM_ITER, 1))\n",
    "  for i in range(NUM_ITER):\n",
    "#     clf = sklearn_lm.SGDClassifier(loss='hinge', eta0=1, learning_rate='constant', penalty='none')\n",
    "#     clf = sklearn_lm.SGDClassifier(loss='squared_loss', penalty='l1')\n",
    "    clf = sklearn_lm.LogisticRegression(penalty='l2')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # predicted label indices \n",
    "    label_idx_pred = []\n",
    "    for c in range(NUM_CLASSES):\n",
    "      label_idx_pred.append(np.asarray([i for i in range(X_test.shape[0]) if y_pred[i] == c+1]))\n",
    "\n",
    "    # draw decision boundaries if 2 features are used\n",
    "#     make_meshplot_multi(X_test[:,2:], label_idx_test, clf,\n",
    "#                     {'x':'PL', 'y':'PW', 'title':'Decision Boundary with Actual Classes'})\n",
    "#     make_meshplot_multi(X_test[:,2:], label_idx_pred, clf, \n",
    "#                     {'x':'PL', 'y':'PW', 'title':'Decision Boundary with Predicted Classes'})\n",
    "    \n",
    "    acc[i] = get_accuracy(y_test, y_pred)\n",
    "#     y_score = clf.predict_proba(X_test)\n",
    "\n",
    "  return acc, clf, y_pred, y_test\n",
    "\n",
    "normalise_data = False\n",
    "acc, clf, y_pred, y_test = linear_classifier(X_train, y_train, X_test, y_test, normalise_data, NUM_ITER)\n",
    "print(np.mean(acc), np.var(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_roc(y_test, y_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs. Rest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshplot_ovr(X, label_idx, clf, kwargs=None):    \n",
    "  h = 0.2 # meshgrid step\n",
    "  NUM_CLASSES = 2\n",
    "  cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])\n",
    "  cmap_bold = ListedColormap(['#FF0000', '#00FF00'])\n",
    "  cmap_color = ['#FF0000', '#00FF00']\n",
    "  \n",
    "  # make meshgraid and decision regions\n",
    "  x1_min, x1_max = X[:,0].min() - 1, X[:, 0].max() + 1\n",
    "  x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "  xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, h),\n",
    "                       np.arange(x2_min, x2_max, h))\n",
    "  dbmesh_pred = clf.predict(np.c_[xx1.ravel(), xx2.ravel()])\n",
    "\n",
    "  # reshape and stack into color plot\n",
    "  dbmesh_pred = dbmesh_pred.reshape(xx1.shape)\n",
    "  mp_plt.figure()\n",
    "  fig = mp_plt.figure(figsize=(8,8))\n",
    "  mp_plt.pcolormesh(xx1, xx2, dbmesh_pred, cmap=cmap_light)\n",
    "\n",
    "  # plot training set\n",
    "  for i in range(2):\n",
    "    mp_plt.scatter(X[label_idx[i], 0], \n",
    "                   X[label_idx[i], 1], \n",
    "                   c = cmap_color[i], cmap=cmap_bold, edgecolor='k', \n",
    "                   label='Class: '+str(i))\n",
    "  mp_plt.xlim(xx1.min(), xx1.max())\n",
    "  mp_plt.ylim(xx2.min(), xx2.max())\n",
    "  if(kwargs):\n",
    "    mp_plt.xlabel(kwargs['x'])\n",
    "    mp_plt.ylabel(kwargs['y'])\n",
    "    mp_plt.title(kwargs['title'])\n",
    "    mp_plt.legend()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_test, y_pred):\n",
    "  return np.float64(sum(y_test == y_pred)) / np.float64(y_test.size)\n",
    "\n",
    "def linear_classifier(X_train, y_train, X_test, y_test, normalise_data, NUM_CLASSES, NUM_ITER):\n",
    "  if(normalise_data):\n",
    "    X_mu = np.mean(X_train, axis=0)\n",
    "    X_var = np.var(X_train, axis=0)\n",
    "    X_train = (X_train - X_mu) / np.sqrt(X_var)\n",
    "    X_test = (X_test - X_mu) / np.sqrt(X_var)\n",
    "  \n",
    "  # randomly sample data from both classes\n",
    "  acc = np.empty((NUM_ITER, 1))\n",
    "  for i in range(NUM_ITER):\n",
    "    clf = sklearn_lm.LogisticRegression(penalty='l2')\n",
    "#     clf = sklearn_lm.SGDClassifier(loss='hinge', eta0=1, learning_rate='constant', penalty='none')\n",
    "#     clf = sklearn_mc.OneVsRestClassifier(sklearn_lm.SGDClassifier(loss='squared_loss', penalty='none'))\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # label indices for predicted classes\n",
    "    label_idx_pred = []\n",
    "    for c in range(NUM_CLASSES):\n",
    "      label_idx_pred.append(np.asarray([i for i in range(X_test.shape[0]) if y_pred[i] == c+1]))\n",
    "    \n",
    "    acc[i] = get_accuracy(y_test, y_pred)\n",
    "\n",
    "  return acc, clf, label_idx_pred\n",
    "\n",
    "normalise_data = False\n",
    "acc, clf, label_idx_pred = linear_classifier(X_train, y_train, X_test, y_test, normalise_data, NUM_CLASSES, NUM_ITER)\n",
    "print(np.mean(acc), np.var(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_act = np.concatenate((np.ones(10, dtype=np.int32), np.zeros(20, dtype=np.int32)))\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "  curr_clf = clf.estimators_[i]\n",
    "  y_pred = curr_clf.predict(X_test[:,2:])\n",
    "\n",
    "  label_idx_act = []\n",
    "  for c in range(2):\n",
    "    label_idx_act.append(np.asarray([i for i in range(X_test.shape[0]) if y_act[i] == c]))\n",
    "  \n",
    "  label_idx_pred = []\n",
    "  for c in range(2):\n",
    "    label_idx_pred.append(np.asarray([i for i in range(X_test.shape[0]) if y_pred[i] == c]))\n",
    "\n",
    "  make_meshplot_ovr(X_test[:,2:], label_idx_act, curr_clf,\n",
    "                    {'x':'PL', 'y':'PW', 'title':'Decision Boundary with Actual Classes'})\n",
    "  make_meshplot_ovr(X_test[:,2:], label_idx_pred, curr_clf,\n",
    "                    {'x':'PL', 'y':'PW', 'title':'Decision Boundary with Predicted Classes'})\n",
    "  \n",
    "  y_act = np.roll(y_act, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs One Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_test, y_pred):\n",
    "  return np.float64(sum(y_test == y_pred)) / np.float64(y_test.size)\n",
    "\n",
    "def linear_classifier(X_train, y_train, X_test, y_test, normalise_data, NUM_ITER):\n",
    "  if(normalise_data):\n",
    "    X_mu = np.mean(X_train, axis=0)\n",
    "    X_var = np.var(X_train, axis=0)\n",
    "    X_train = (X_train - X_mu) / np.sqrt(X_var)\n",
    "    X_test = (X_test - X_mu) / np.sqrt(X_var)\n",
    "  \n",
    "  # randomly sample data from both classes\n",
    "  acc = np.empty((NUM_ITER, 1))\n",
    "  for i in range(NUM_ITER):\n",
    "    clf = sklearn_mc.OneVsOneClassifier(sklearn_lm.SGDClassifier(loss='log', penalty='none'))\n",
    "    clf.fit(X_train[:,2:], y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test[:,2:])\n",
    "    acc[i] = get_accuracy(y_test, y_pred)\n",
    "\n",
    "  return acc, clf\n",
    "\n",
    "normalise_data = False\n",
    "acc, clf = linear_classifier(X_train, y_train, X_test, y_test, normalise_data, 1)\n",
    "print(np.mean(acc), np.var(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_act = np.concatenate((np.ones(10, dtype=np.int32), np.zeros(20, dtype=np.int32)))\n",
    "\n",
    "for i in range(NUM_CLASSES):\n",
    "  curr_clf = clf.estimators_[i]\n",
    "  y_pred = curr_clf.predict(X_test[:,2:])\n",
    "\n",
    "  label_idx_act = []\n",
    "  for c in range(2):\n",
    "    label_idx_act.append(np.asarray([i for i in range(X_test.shape[0]) if y_act[i] == c]))\n",
    "  \n",
    "  label_idx_pred = []\n",
    "  for c in range(2):\n",
    "    label_idx_pred.append(np.asarray([i for i in range(X_test.shape[0]) if y_pred[i] == c]))\n",
    "\n",
    "  make_meshplot_ovr(X_test[:,2:], label_idx_act, curr_clf,\n",
    "                    {'x':'PL', 'y':'PW', 'title':'Decision Boundary with Actual Classes'})\n",
    "  make_meshplot_ovr(X_test[:,2:], label_idx_pred, curr_clf,\n",
    "                    {'x':'PL', 'y':'PW', 'title':'Decision Boundary with Predicted Classes'})\n",
    "  \n",
    "  y_act = np.roll(y_act, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Boundaries for Multiclass-Classification using two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meshplot(X, label_idx, clf, kwargs=None):    \n",
    "  h = 0.2 # meshgrid step\n",
    "  NUM_CLASSES = 3\n",
    "  cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "  cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "  cmap_color = ['#FF0000', '#00FF00', '#0000FF']\n",
    "  \n",
    "  # make meshgraid and decision regions\n",
    "  x1_min, x1_max = X[:,0].min() - 1, X[:, 0].max() + 1\n",
    "  x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "  xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, h),\n",
    "                       np.arange(x2_min, x2_max, h))\n",
    "  dbmesh_pred = clf.predict(np.c_[xx1.ravel(), xx2.ravel()])\n",
    "\n",
    "  # reshape and stack into color plot\n",
    "  dbmesh_pred = dbmesh_pred.reshape(xx1.shape)\n",
    "  mp_plt.figure()\n",
    "  fig = mp_plt.figure(figsize=(8,8))\n",
    "  mp_plt.pcolormesh(xx1, xx2, dbmesh_pred, cmap=cmap_light)\n",
    "\n",
    "  # plot training set\n",
    "  for i in range(NUM_CLASSES):\n",
    "    mp_plt.scatter(X[label_idx[i], 0], \n",
    "                   X[label_idx[i], 1], \n",
    "                   c=cmap_color[i], edgecolor='k', cmap=cmap_bold,\n",
    "                   label='Class: '+str(i+1))\n",
    "  mp_plt.xlim(xx1.min(), xx1.max())\n",
    "  mp_plt.ylim(xx2.min(), xx2.max())\n",
    "  if(kwargs):\n",
    "    mp_plt.xlabel(kwargs['x'])\n",
    "    mp_plt.ylabel(kwargs['y'])\n",
    "    mp_plt.title(kwargs['title'])\n",
    "  mp_plt.legend()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_test, y_pred):\n",
    "  return np.float64(sum(y_test == y_pred)) / np.float64(y_test.size)\n",
    "\n",
    "def linear_classifier(X_train, y_train, X_test, y_test, label_idx, normalise_data, NUM_CLASSES, NUM_ITER):\n",
    "  if(normalise_data):\n",
    "    X_mu = np.mean(X_train, axis=0)\n",
    "    X_var = np.var(X_train, axis=0)\n",
    "    X_train = (X_train - X_mu) / np.sqrt(X_var)\n",
    "    X_test = (X_test - X_mu) / np.sqrt(X_var)\n",
    "  \n",
    "  # randomly sample data from both classes\n",
    "  acc = np.empty((NUM_ITER, 1))\n",
    "  for i in range(NUM_ITER):\n",
    "    clf = sklearn_lm.SGDClassifier(loss='log', penalty='none')\n",
    "    clf.fit(X_train[:,2:], y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test[:,2:])\n",
    "    \n",
    "    # label indices for predicted classes\n",
    "    label_idx_pred = []\n",
    "    for c in range(NUM_CLASSES):\n",
    "      label_idx_pred.append(np.asarray([i for i in range(X_test.shape[0]) if y_pred[i] == c+1]))\n",
    "    \n",
    "    make_meshplot(X_test[:,2:], label_idx, clf, {'x':'PL', 'y':'PW', 'title':'Decision Boundary with Actual Classes'})\n",
    "    make_meshplot(X_test[:,2:], label_idx_pred, clf, {'x':'PL', 'y':'PW', 'title':'Decision Boundary with Predicted Classes'})\n",
    "\n",
    "    acc[i] = get_accuracy(y_test, y_pred)\n",
    "\n",
    "  return acc\n",
    "\n",
    "normalise_data = True\n",
    "acc = linear_classifier(X_train, y_train, X_test, y_test, label_idx_test, normalise_data, NUM_CLASSES, NUM_ITER)\n",
    "print(np.mean(acc), np.var(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
